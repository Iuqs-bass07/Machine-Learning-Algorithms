{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb9aa09",
   "metadata": {},
   "source": [
    "### Linear Regression Implementation using Gradient Descent\n",
    "\n",
    "Here we are implementing the linear regression using gradient descent. We will pick the Loss function and then calculate the derivative of it with respect to the slope and intercept, and then, in each epoch, we will update it.\n",
    "\n",
    "1. **Write the Loss Function**\n",
    "   - \\( L = \\sum (y_i - y_{pred})^2 \\)\n",
    "\n",
    "2. **Initialize some values of the m and b**\n",
    "\n",
    "3. **In each epoch, calculate the partial derivative of m and b**\n",
    "\n",
    "4. **Update the values of m and b**\n",
    "   - \\( b_{\\text{new}} = b_{\\text{old}} - \\text{learning\\_rate} \\times \\frac{dL}{db} \\)\n",
    "   - \\( m_{\\text{new}} = m_{\\text{old}} - \\text{learning\\_rate} \\times \\frac{dL}{dm} \\)\n",
    "\n",
    "The partial derivative has been calculated and fed into each epoch and updated repeatedly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5f9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60b8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # update all the coef and the intercept\n",
    "            y_hat = np.dot(X_train,self.coef_) + self.intercept_\n",
    "            #print(\"Shape of y_hat\",y_hat.shape)\n",
    "            intercept_der = -2 * np.mean(y_train - y_hat)\n",
    "            self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "            \n",
    "            coef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
    "            self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8cbe8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1da4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5716d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3190dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing it on the dataset and comparing it with the sklearn\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "986cb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571634ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caaf4396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac9df14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.16088483 -205.46225988  516.68462383  340.62734108 -895.54360867\n",
      "  561.21453306  153.88478595  126.73431596  861.12139955   52.41982836]\n",
      "151.8833452085463\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2504bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015305593565441589"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7190ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now testing our own model\n",
    "gdr = MyGDRegressor(epochs=1000,learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c155fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.0135263267291 [  14.38915082 -173.72674118  491.54504015  323.91983579  -39.32680194\n",
      " -116.01099114 -194.04229501  103.38216641  451.63385893   97.57119174]\n"
     ]
    }
   ],
   "source": [
    "gdr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e971d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8607829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63de87aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04225644685048091"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0caa9",
   "metadata": {},
   "source": [
    "### We can see from here that the coefficient from the both sklearn and our own class matches very well & r2score of the both techniques matches very well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a76fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
