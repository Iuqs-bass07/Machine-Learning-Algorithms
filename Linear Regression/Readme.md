## This repository contains an implementation of a Linear Regressor from scratch in Python, covering three different approaches:

Closed Form Solution (Normal Equation)
Batch Gradient Descent
Stochastic Gradient Descent

- Overview
Linear regression is a fundamental algorithm in machine learning that models the relationship between a dependent variable and one or more independent variables. This project demonstrates how to implement a Linear Regressor using three approaches:

### Closed Form Solution (Normal Equation): 
    Computes the optimal weights directly using a mathematical formula without the need for iterative optimization.

### Batch Gradient Descent: 
An iterative optimization technique where the entire dataset is used to update the model parameters in each iteration.

### Stochastic Gradient Descent (SGD): 
An iterative method similar to batch gradient descent, but it updates the model parameters using a single data point (or a small batch) in each iteration, making it faster for large datasets.
