{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8678fcc0",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Implementation\n",
    "\n",
    "Here we are implementing linear regression using stochastic gradient descent. In this method, instead of using the entire dataset for each update, we use one data point (or a small batch) at a time to update the model parameters.\n",
    "\n",
    "1. **Write the Loss Function**\n",
    "   - \\( L = (y_i - y_{pred})^2 \\)\n",
    "\n",
    "2. **Initialize some values for the parameters m and b**\n",
    "\n",
    "3. **Iterate through each epoch and for each data point (x, y) in the dataset:**\n",
    "   - a. **Compute the predicted value** \\( y_{pred} = mx + b \\)\n",
    "   - b. **Calculate the gradients** (partial derivatives):\n",
    "     - \\( \\frac{\\partial L}{\\partial m} = -2 \\times x \\times (y - y_{pred}) \\)\n",
    "     - \\( \\frac{\\partial L}{\\partial b} = -2 \\times (y - y_{pred}) \\)\n",
    "\n",
    "4. **Update the values of m and b**:\n",
    "   - \\( b_{\\text{new}} = b_{\\text{old}} - \\text{learning\\_rate} \\times \\frac{\\partial L}{\\partial b} \\)\n",
    "   - \\( m_{\\text{new}} = m_{\\text{old}} - \\text{learning\\_rate} \\times \\frac{\\partial L}{\\partial m} \\)\n",
    "\n",
    "5. **Repeat the process for the specified number of epochs** to minimize the loss function.\n",
    "\n",
    "By using one data point at a time, the model parameters are updated frequently, leading to faster convergence, but with potentially more variance in updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159494b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5032e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    \n",
    "    def __init__(self, epochs = 1000, learning_rate = 0.01):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.epochs = epochs\n",
    "        self.lr = learning_rate\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                \n",
    "                #picking a random row from 0 to total rows\n",
    "                idx = np.random.randint(0,X_train.shape[0])\n",
    "                \n",
    "                #calculating the prediction for that row(Scalar)\n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                # derivative for the intercept(only for that row) and update\n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                #derivative for the coeff(only wrt that row) and update\n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        return np.dot(X_test, self.coef_) + self.intercept_\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5b737c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn model regressor\n",
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2137e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39e1173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f5f7c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1434592396027481"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c86a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our own clas performance\n",
    "sgd = SGDRegressor(epochs = 1000, learning_rate = 0.01)\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1b360fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05c0f264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11592890624431362"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba72078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb456876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
